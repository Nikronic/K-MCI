{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-MCI\n",
    "### Intro\n",
    "In this notebook we have the main algorithm of the article. All necessary functions are implemented in function.py file.<br>\n",
    "This document have blow sections:<br>\n",
    "1. Importing Libraries & classes\n",
    "2. Reading datasets\n",
    "3. Preprocessing datasets\n",
    "4. Main Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries & classes\n",
    "We import some libraries from third party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import copy\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defnition of Candidate class\n",
    "class Candidate:    \n",
    "    def __init__(self,nodes,sampling_interval,fitness=-1):\n",
    "        self.nodes = nodes\n",
    "        self.sampling_interval = sampling_interval \n",
    "        self.variation = []\n",
    "        self.random_number\n",
    "        self.fitness = fitness\n",
    "        self.centers = []\n",
    "        self.probability = []\n",
    "        self.labels = []\n",
    "        self.each_fitness = []\n",
    "        \n",
    "    def random_number(self):\n",
    "        self.random_number = random.random()\n",
    "        \n",
    "    def describe(self):\n",
    "        print(\"Candidate with #{} nodes, #{} centers, fitness={}\\n clusters:\\n{} \\n Centers:\\n{}\\n sampling_interval:\\n{}\"\n",
    "              .format(len(self.nodes),len(self.centers),self.fitness,self.nodes[np.random.randint(self.nodes.shape[0], size=5), :],self.centers,self.sampling_interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Datasets and Preprocessing\n",
    "We show the structure of our data for all of datasets.<br>\n",
    "We have these datasets from UCI Machine Learning Repository:\n",
    "1. Breast Cancer Wisconsin\n",
    "2. Contraceptive Method Choice data\n",
    "3. Glass\n",
    "4. Iris\n",
    "5. Vowel\n",
    "6. Wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" In this cell we have some code which will do preprocessing for us on all datasets \"\"\"\n",
    "\"\"\" the resourses of these datasets are mentioned in README.md file. \"\"\"\n",
    "\n",
    "path = 'datasets/' \n",
    "# because we are using local files, you need to download datasets and change the \"path\" variable\n",
    "# local folder of your downloaded datasets\n",
    "\n",
    "\n",
    "def bcw(): \n",
    "    # importing dataset\n",
    "    dataset = pd.read_csv(path+'bcw.csv',\n",
    "                          names = ['Sample code number','Clump Thickness','Uniformity of Cell Size',\n",
    "                                   'Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial',\n",
    "                                   'Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class'])\n",
    "    dataset = dataset.drop(dataset.columns[0], axis=1)\n",
    "    dataset= dataset.replace(to_replace='?',value=np.nan)\n",
    "    dataset = dataset.dropna(axis =0) # resolving missing values\n",
    "    dataset = dataset.astype('int64') # casting string valued column to int64\n",
    "    x = dataset.iloc[:,:-1].values # features\n",
    "    y = dataset.iloc[:,-1].values # target values\n",
    "    return (x,y,dataset)\n",
    "\n",
    "\n",
    "def cmc():\n",
    "    # importing dataset\n",
    "    dataset = pd.read_csv(path+'cmc.csv', names=[\"Wife's age\",\"Wife's education\",\"Husband's education\",\n",
    "                                                 \"Number of children ever born\",\"Wife's religion\",\n",
    "                                                 \"Wife's now working?\",\"Husband's occupation\",\n",
    "                                                 \"Standard-of-living index\",\"Media exposure\",\"Contraceptive method used\"])\n",
    "    x = dataset.iloc[:,:-1].values # features\n",
    "    y = dataset.iloc[:,-1].values # target values\n",
    "    return (x,y,dataset)\n",
    "\n",
    "\n",
    "def glass():\n",
    "    # importing dataset\n",
    "    dataset = pd.read_csv(path+'glass.csv', names= ['Id','refractive index','Sodium','Magnesium','Aluminum','Silicon','Potassium'\n",
    "                                                    ,'Calcium','Barium','Iron','glass'])\n",
    "    x = dataset.iloc[:,1:10].values # features\n",
    "    y = dataset.iloc[:,-1].values # target values\n",
    "    return (x,y,dataset)\n",
    "\n",
    "\n",
    "def iris():\n",
    "    # importing dataset\n",
    "    dataset = pd.read_csv(path+'iris.csv', names= ['sepal length','sepal width','petal length','petal width','class'])\n",
    "    x = dataset.iloc[:,:-1].values # features\n",
    "    y = dataset.iloc[:,-1].values # target values\n",
    "    \n",
    "    # encoding categorial data types to labelEncoder\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    labelencoder_y = LabelEncoder()\n",
    "    labelencoder_y = labelencoder_y.fit(y)\n",
    "    y = labelencoder_y.transform(y)  # 0 for 'Iris-setosa', 1 for 'Iris-versicolor', 2 for 'Iris-virginica'\n",
    "    return (x,y,dataset)\n",
    "\n",
    "\n",
    "def vowel():\n",
    "    # importing dataset\n",
    "    dataset = pd.read_csv(path+'vowel.csv', names= ['vowel','type 1 frq','type 2 frq','type 3 frq'])\n",
    "    x = dataset.iloc[:,1:].values # features\n",
    "    y = dataset.iloc[:,0].values # target values\n",
    "    return (x,y,dataset)\n",
    "\n",
    "def wine():\n",
    "    # importing dataset\n",
    "    dataset = pd.read_csv(path+'wine.csv', names= ['class','Alcohol','Malic acid','Ash','Alcalinity of ash','Magnesium','Total phenols','Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue','OD280/OD315','Proline'])\n",
    "    x = dataset.iloc[:,1:].values # features\n",
    "    y = dataset.iloc[:,0].values # target values\n",
    "    return (x,y,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting data from our preprocessing class Datasets\n",
    "x_bcw, y_bcw, df_bcw = bcw()\n",
    "x_cmc, y_cmc, df_cmc = cmc()\n",
    "x_glass, y_glass, df_glass = glass()\n",
    "x_iris, y_iris, df_iris = iris()\n",
    "x_vowel, y_vowel, df_vowel = vowel()\n",
    "x_wine, y_wine, df_wine = wine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0                5                        1                         1   \n",
       "1                5                        4                         4   \n",
       "2                3                        1                         1   \n",
       "\n",
       "   Marginal Adhesion  Single Epithelial  Bare Nuclei  Bland Chromatin  \\\n",
       "0                  1                  2            1                3   \n",
       "1                  5                  7           10                3   \n",
       "2                  1                  2            2                3   \n",
       "\n",
       "   Normal Nucleoli  Mitoses  Class  \n",
       "0                1        1      2  \n",
       "1                2        1      2  \n",
       "2                1        1      2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing dataset of Breast Cancer Wisconsin\n",
    "df_bcw.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wife's age</th>\n",
       "      <th>Wife's education</th>\n",
       "      <th>Husband's education</th>\n",
       "      <th>Number of children ever born</th>\n",
       "      <th>Wife's religion</th>\n",
       "      <th>Wife's now working?</th>\n",
       "      <th>Husband's occupation</th>\n",
       "      <th>Standard-of-living index</th>\n",
       "      <th>Media exposure</th>\n",
       "      <th>Contraceptive method used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wife's age  Wife's education  Husband's education  \\\n",
       "0          24                 2                    3   \n",
       "1          45                 1                    3   \n",
       "2          43                 2                    3   \n",
       "\n",
       "   Number of children ever born  Wife's religion  Wife's now working?  \\\n",
       "0                             3                1                    1   \n",
       "1                            10                1                    1   \n",
       "2                             7                1                    1   \n",
       "\n",
       "   Husband's occupation  Standard-of-living index  Media exposure  \\\n",
       "0                     2                         3               0   \n",
       "1                     3                         4               0   \n",
       "2                     3                         4               0   \n",
       "\n",
       "   Contraceptive method used  \n",
       "0                          1  \n",
       "1                          1  \n",
       "2                          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing dataset of Contraceptive Method Choice data\n",
    "df_cmc.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>refractive index</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Aluminum</th>\n",
       "      <th>Silicon</th>\n",
       "      <th>Potassium</th>\n",
       "      <th>Calcium</th>\n",
       "      <th>Barium</th>\n",
       "      <th>Iron</th>\n",
       "      <th>glass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  refractive index  Sodium  Magnesium  Aluminum  Silicon  Potassium  \\\n",
       "0   1           1.52101   13.64       4.49      1.10    71.78       0.06   \n",
       "1   2           1.51761   13.89       3.60      1.36    72.73       0.48   \n",
       "2   3           1.51618   13.53       3.55      1.54    72.99       0.39   \n",
       "\n",
       "   Calcium  Barium  Iron  glass  \n",
       "0     8.75     0.0   0.0      1  \n",
       "1     7.83     0.0   0.0      1  \n",
       "2     7.78     0.0   0.0      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing dataset of Glass\n",
    "df_glass.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing dataset of Iris\n",
    "df_iris.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vowel</th>\n",
       "      <th>type 1 frq</th>\n",
       "      <th>type 2 frq</th>\n",
       "      <th>type 3 frq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>1500</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>550</td>\n",
       "      <td>1550</td>\n",
       "      <td>2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>700</td>\n",
       "      <td>1500</td>\n",
       "      <td>2600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vowel  type 1 frq  type 2 frq  type 3 frq\n",
       "0      1         700        1500        2600\n",
       "1      1         550        1550        2400\n",
       "2      1         700        1500        2600"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing dataset of Vowel\n",
    "df_vowel.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315  Proline  \n",
       "0             5.64  1.04         3.92     1065  \n",
       "1             4.38  1.05         3.40     1050  \n",
       "2             5.68  1.03         3.17     1185  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Showing dataset of Wine\n",
    "df_wine.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization\n",
    "In this cell, we standard our data using this equation: <img src='http://3.bp.blogspot.com/_xqXlcaQiGRk/RpO4yR0oKtI/AAAAAAAAABM/7rUWCMwizus/s200/fig2.png'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaMeD\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "x_bcw = preprocessing.scale(x_bcw)\n",
    "x_wine = preprocessing.scale(x_wine)\n",
    "x_cmc = preprocessing.scale(x_cmc)\n",
    "#x_glass = preprocessing.scale(x_glass)\n",
    "x_iris = preprocessing.scale(x_iris)\n",
    "x_vowel = preprocessing.scale(x_vowel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Algorithm \n",
    "\n",
    "The implementation of main algorithm have below sections:\n",
    "1. <Strong>Initializing Parameters and Candidates</Strong>\n",
    "    1. Sampling Interval\n",
    "    2. Apply Random Centers to Candidates\n",
    "    3. Visualizing Candidates\n",
    "2. <Strong>Running Kmean to Exploit</Strong>\n",
    "    1. K-means Algorithm\n",
    "    2. Visualizing Candidates\n",
    "3. <Strong>Mutation Algorithm</Strong>\n",
    "    1. Fitness over Mutated Candidate\n",
    "    2. Probablility Equation\n",
    "    3. Mutation Logic\n",
    "\n",
    "**Extra details will be explain in other next sections**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing Parameters and Candidates\n",
    "In this step, we initialize our algorithm. There are some parameters which are important to convergance speed and quality of solution. So we initialize them here based on the paper.<br>\n",
    "Each time you want to run K-MCI algorithm, you should first do this initialization.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice: this values related to IRIS dataset\n",
    "candidates_array = [] # the array of all candidates\n",
    "number_of_candidates = 5\n",
    "sampling_interval_reduction_factor = 0.95\n",
    "convergence_parameter = None # what is this in paper???\n",
    "mutation_random = 0.7\n",
    "iterations_count = 3500\n",
    "variations_count = 15\n",
    "number_of_clusters = 6 # in this article number of clusters are predefined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling Interval\n",
    "this function use for making sampling_interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_intervals(input_array):\n",
    "    Maxes = np.amax(input_array,axis=0)\n",
    "    Mins  = np.amin(input_array,axis=0)\n",
    "    return (Maxes,Mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing candidates\n",
    "for i in range(0 ,number_of_candidates):\n",
    "    candidates_array.append(Candidate(x_glass,sampling_interval = sampling_intervals(x_glass)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Candidates\n",
    "some parameters are uninitialized. They will have value after running Kmean and Cohort and mutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate with #214 nodes, #0 centers, fitness=-1\n",
      " clusters:\n",
      "[[ 1.52058 12.85     1.61     2.17    72.18     0.76     9.7      0.24\n",
      "   0.51   ]\n",
      " [ 1.51892 13.46     3.83     1.26    72.55     0.57     8.21     0.\n",
      "   0.14   ]\n",
      " [ 1.51898 13.58     3.35     1.23    72.08     0.59     8.91     0.\n",
      "   0.     ]\n",
      " [ 1.51776 13.53     3.41     1.52    72.04     0.58     8.79     0.\n",
      "   0.     ]\n",
      " [ 1.51892 13.46     3.83     1.26    72.55     0.57     8.21     0.\n",
      "   0.14   ]] \n",
      " Centers:\n",
      "[]\n",
      " sampling_interval:\n",
      "(array([ 1.53393, 17.38   ,  4.49   ,  3.5    , 75.41   ,  6.21   ,\n",
      "       16.19   ,  3.15   ,  0.51   ]), array([ 1.51115, 10.73   ,  0.     ,  0.29   , 69.81   ,  0.     ,\n",
      "        5.43   ,  0.     ,  0.     ]))\n"
     ]
    }
   ],
   "source": [
    "candidates_array[random.randint(0,number_of_candidates-1)].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Random Centers to Candidates\n",
    "In this step, we just select some random nodes as centers with psuedorandom functions in python native library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.51727 14.7      0.       2.34    73.28     0.       8.95     0.66\n",
      "   0.     ]\n",
      " [ 1.51652 13.56     3.57     1.47    72.45     0.64     7.96     0.\n",
      "   0.     ]\n",
      " [ 1.51832 13.33     3.34     1.54    72.14     0.56     8.99     0.\n",
      "   0.     ]\n",
      " [ 1.51839 12.85     3.67     1.24    72.57     0.62     8.68     0.\n",
      "   0.35   ]\n",
      " [ 1.51796 13.5      3.36     1.63    71.94     0.57     8.81     0.\n",
      "   0.09   ]\n",
      " [ 1.51824 12.87     3.48     1.29    72.95     0.6      8.43     0.\n",
      "   0.     ]]\n",
      "[[ 1.51937 13.79     2.41     1.19    72.76     0.       9.77     0.\n",
      "   0.     ]\n",
      " [ 1.51613 13.88     1.78     1.79    73.1      0.       8.67     0.76\n",
      "   0.     ]\n",
      " [ 1.52213 14.21     3.82     0.47    71.77     0.11     9.57     0.\n",
      "   0.     ]\n",
      " [ 1.51727 14.7      0.       2.34    73.28     0.       8.95     0.66\n",
      "   0.     ]\n",
      " [ 1.5164  14.37     0.       2.74    72.85     0.       9.45     0.54\n",
      "   0.     ]\n",
      " [ 1.51618 13.01     3.5      1.48    72.89     0.6      8.12     0.\n",
      "   0.     ]]\n",
      "[[ 1.51514 14.85     0.       2.42    73.72     0.       8.39     0.56\n",
      "   0.     ]\n",
      " [ 1.51839 12.85     3.67     1.24    72.57     0.62     8.68     0.\n",
      "   0.35   ]\n",
      " [ 1.5169  13.33     3.54     1.61    72.54     0.68     8.11     0.\n",
      "   0.     ]\n",
      " [ 1.51215 12.99     3.47     1.12    72.98     0.62     8.35     0.\n",
      "   0.31   ]\n",
      " [ 1.51783 12.69     3.54     1.34    72.95     0.57     8.75     0.\n",
      "   0.     ]\n",
      " [ 1.51754 13.48     3.74     1.17    72.99     0.59     8.03     0.\n",
      "   0.     ]]\n",
      "[[1.51769e+00 1.24500e+01 2.71000e+00 1.29000e+00 7.37000e+01 5.60000e-01\n",
      "  9.06000e+00 0.00000e+00 2.40000e-01]\n",
      " [1.51911e+00 1.39000e+01 3.73000e+00 1.18000e+00 7.21200e+01 6.00000e-02\n",
      "  8.89000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.51969e+00 1.26400e+01 0.00000e+00 1.65000e+00 7.37500e+01 3.80000e-01\n",
      "  1.15300e+01 0.00000e+00 0.00000e+00]\n",
      " [1.51779e+00 1.32100e+01 3.39000e+00 1.33000e+00 7.27600e+01 5.90000e-01\n",
      "  8.59000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.51916e+00 1.41500e+01 0.00000e+00 2.09000e+00 7.27400e+01 0.00000e+00\n",
      "  1.08800e+01 0.00000e+00 0.00000e+00]\n",
      " [1.52119e+00 1.29700e+01 3.30000e-01 1.51000e+00 7.33900e+01 1.30000e-01\n",
      "  1.12700e+01 0.00000e+00 2.80000e-01]]\n",
      "[[1.51590e+00 1.32400e+01 3.34000e+00 1.47000e+00 7.31000e+01 3.90000e-01\n",
      "  8.22000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.51605e+00 1.29000e+01 3.44000e+00 1.45000e+00 7.30600e+01 4.40000e-01\n",
      "  8.27000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.52369e+00 1.34400e+01 0.00000e+00 1.58000e+00 7.22200e+01 3.20000e-01\n",
      "  1.22400e+01 0.00000e+00 0.00000e+00]\n",
      " [1.51574e+00 1.48600e+01 3.67000e+00 1.74000e+00 7.18700e+01 1.60000e-01\n",
      "  7.36000e+00 0.00000e+00 1.20000e-01]\n",
      " [1.51742e+00 1.32700e+01 3.62000e+00 1.24000e+00 7.30800e+01 5.50000e-01\n",
      "  8.07000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.51531e+00 1.43800e+01 0.00000e+00 2.66000e+00 7.31000e+01 4.00000e-02\n",
      "  9.08000e+00 6.40000e-01 0.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "for c in range(0,number_of_candidates):\n",
    "    candidates_array[c].centers =  np.asarray(random.sample(list(candidates_array[c].nodes),number_of_clusters))\n",
    "    print(candidates_array[c].centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Algorithm \n",
    "this function fitting k-means model on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doKmeans(x,clusters_count,init_centers):\n",
    "    kmeans = KMeans(n_clusters = clusters_count, init = init_centers,n_init = 50)\n",
    "    kmeans = kmeans.fit(x)\n",
    "    labels = kmeans.labels_\n",
    "    return (labels,kmeans.cluster_centers_,kmeans.inertia_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Kmean to Exploit\n",
    "Here by running Kmean on all of our candidates, they centers initialized and nodes assigns to clusters based on Kmean++ algorithm.<br>\n",
    "The objective function of Kmean is also the object function of K-MCI. <br>\n",
    "So the fitness of any candidates is calculated using Kmean inertia or mean square error of nodes to their centers distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaMeD\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:896: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=50\n",
      "  return_n_iter=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 1, 5, 3, 3, 1,\n",
       "       3, 3, 5, 3, 5, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 3, 1, 1, 3, 3, 3, 1,\n",
       "       3, 5, 3, 1, 1, 5, 1, 5, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 5, 5, 3, 5, 3, 3, 5, 3, 5, 3, 3, 3, 5, 3, 5, 5, 3, 5,\n",
       "       3, 3, 5, 3, 3, 3, 3, 5, 5, 3, 3, 3, 3, 3, 3, 1, 1, 4, 4, 4, 4, 0,\n",
       "       4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 3, 3, 5, 5, 3, 3, 1, 1, 1, 4, 4,\n",
       "       5, 5, 5, 5, 3, 3, 3, 3, 5, 3, 3, 3, 3, 3, 5, 5, 5, 3, 5, 1, 5, 5,\n",
       "       3, 3, 5, 1, 5, 5, 5, 5, 1, 2, 1, 4, 4, 4, 0, 4, 4, 2, 2, 4, 1, 4,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 2, 2, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for c in range(0,number_of_candidates):\n",
    "    y_predict_temp,centers_temp,fitness_temp = doKmeans(candidates_array[c].nodes,clusters_count = number_of_clusters,init_centers = candidates_array[c].centers)\n",
    "    candidates_array[c].centers = centers_temp\n",
    "    candidates_array[c].fitness = fitness_temp\n",
    "    candidates_array[c].labels   = y_predict_temp\n",
    "    \n",
    "candidates_array[2].labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Candidates\n",
    "In this step, by Kmeans, we assigned centers to each candidates and calculated the fitness of each candidate using inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate with #214 nodes, #6 centers, fitness=379.1282755933587\n",
      " clusters:\n",
      "[[1.51852e+00 1.40900e+01 2.19000e+00 1.66000e+00 7.26700e+01 0.00000e+00\n",
      "  9.32000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.51735e+00 1.30200e+01 3.54000e+00 1.69000e+00 7.27300e+01 5.40000e-01\n",
      "  8.44000e+00 0.00000e+00 7.00000e-02]\n",
      " [1.51593e+00 1.32500e+01 3.45000e+00 1.43000e+00 7.31700e+01 6.10000e-01\n",
      "  7.86000e+00 0.00000e+00 0.00000e+00]\n",
      " [1.51670e+00 1.32400e+01 3.57000e+00 1.38000e+00 7.27000e+01 5.60000e-01\n",
      "  8.44000e+00 0.00000e+00 1.00000e-01]\n",
      " [1.51811e+00 1.29600e+01 2.96000e+00 1.43000e+00 7.29200e+01 6.00000e-01\n",
      "  8.79000e+00 1.40000e-01 0.00000e+00]] \n",
      " Centers:\n",
      "[[1.52352895e+00 1.27352632e+01 2.59473684e-01 1.32210526e+00\n",
      "  7.25357895e+01 2.56315789e-01 1.25184211e+01 1.65789474e-01\n",
      "  6.94736842e-02]\n",
      " [1.51632464e+00 1.45125000e+01 1.53571429e-01 2.08500000e+00\n",
      "  7.34007143e+01 1.96785714e-01 8.64964286e+00 9.16428571e-01\n",
      "  1.39285714e-02]\n",
      " [1.52165781e+00 1.38634375e+01 3.11437500e+00 1.07187500e+00\n",
      "  7.18084375e+01 1.99375000e-01 9.73843750e+00 6.84375000e-02\n",
      "  7.40625000e-02]\n",
      " [1.51770052e+00 1.34889655e+01 3.60482759e+00 1.35603448e+00\n",
      "  7.24534483e+01 5.35000000e-01 8.32775862e+00 3.68965517e-02\n",
      "  4.87931034e-02]\n",
      " [1.51497250e+00 1.35875000e+01 1.48500000e+00 2.94500000e+00\n",
      "  7.05800000e+01 3.89000000e+00 6.38750000e+00 9.57500000e-01\n",
      "  0.00000000e+00]\n",
      " [1.51707521e+00 1.28852055e+01 3.43260274e+00 1.38328767e+00\n",
      "  7.30330137e+01 5.89315068e-01 8.44602740e+00 6.71232877e-03\n",
      "  7.24657534e-02]]\n",
      " sampling_interval:\n",
      "(array([ 1.53393, 17.38   ,  4.49   ,  3.5    , 75.41   ,  6.21   ,\n",
      "       16.19   ,  3.15   ,  0.51   ]), array([ 1.51115, 10.73   ,  0.     ,  0.29   , 69.81   ,  0.     ,\n",
      "        5.43   ,  0.     ,  0.     ]))\n"
     ]
    }
   ],
   "source": [
    "candidates_array[random.randint(0,number_of_candidates-1)].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379.1282755933587"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_of_squares(candidates_array[0].nodes,candidates_array[0].centers,candidates_array[0].labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitness over Mutated Candidate\n",
    "Just simple sum of square of distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_squares(data, centroids, labels):\n",
    "    sqe = 0\n",
    "    for l in np.unique(labels):\n",
    "        data_l = data[labels == l]\n",
    "        resid = data_l - centroids[l]\n",
    "        sqe += (resid**2).sum()\n",
    "    return sqe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Distance to a Specific Center\n",
    "This function is exactly based on \"sum_of_squares\" function. But here all centers not engaged because we want to find the sum of square distances of nodes of a cluster to their cluster center.<br>\n",
    "The idea is when mutation process done, at least one dimension may get better center but the other goes bad. So we want to have that center which is better to the previous time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_dist(data, center, labels, center_position, center_cluster):\n",
    "    sqe = 0\n",
    "    for l in range(0,len(labels)):\n",
    "        if center_cluster == labels[l] :\n",
    "            data_l = data[l][center_position]\n",
    "            resid = data_l - center\n",
    "            sqe += (resid**2)\n",
    "    return sqe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.36024579e-04 2.77644737e+01 6.30829474e+00 4.45571579e+00\n",
      "  2.41770632e+01 1.06804211e+00 4.53240526e+01 9.40026316e+00\n",
      "  2.54694737e-01]\n",
      " [7.66932964e-05 2.09117250e+01 6.14404286e+00 7.62950000e+00\n",
      "  1.19303857e+01 9.17281071e+00 1.65754964e+01 1.33504429e+01\n",
      "  2.46678571e-02]\n",
      " [1.22133147e-04 1.22829219e+01 2.16421875e+01 7.40928750e+00\n",
      "  1.11758219e+01 1.42498750e+00 9.22562187e+00 2.80302187e+00\n",
      "  4.48571875e-01]\n",
      " [1.73468684e-04 5.59073793e+00 2.79664828e+00 3.41838793e+00\n",
      "  6.72971034e+00 3.53945000e+00 1.85716086e+01 1.84784138e+00\n",
      "  4.22615517e-01]\n",
      " [1.80306750e-05 1.38227500e+00 8.98910000e+00 8.48300000e-01\n",
      "  9.49400000e-01 2.15538000e+01 1.24687500e+00 3.82967500e+00\n",
      "  0.00000000e+00]\n",
      " [7.47750219e-05 4.24982192e+00 4.53400548e+00 3.38541096e+00\n",
      "  4.04053699e+00 6.26865753e-01 8.84894795e+00 4.82109589e-02\n",
      "  7.73156164e-01]]\n"
     ]
    }
   ],
   "source": [
    "def each_fitness(candidates_array_example):\n",
    "    fitness_of_each_centers = []\n",
    "    for i in range(0,len(candidates_array_example.centers)):\n",
    "        Second_layer = []\n",
    "        for j in range(0,len(candidates_array_example.centers[i])):\n",
    "            Second_layer.append(center_dist(candidates_array_example.nodes,candidates_array_example.centers[i][j],candidates_array_example.labels,j,i))\n",
    "        fitness_of_each_centers.append(Second_layer)\n",
    "    return np.array(fitness_of_each_centers)\n",
    "print(each_fitness(candidates_array[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test paper own answer\n",
    "## result:\n",
    "**paper has wrong answer and numbers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 4, 4, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 3, 3, 4, 4, 4, 3, 4, 3, 4, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 0, 0, 0, 1, 1, 0, 0, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 1, 1, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 3, 3, 3, 5, 5, 1, 1, 5, 4, 4, 4, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "343.7814274034\n",
      "379.1282755933587\n"
     ]
    }
   ],
   "source": [
    "def just_test(data,center):\n",
    "    temp1 = np.subtract(center,data)\n",
    "    temp1 = np.power(temp1, 2)\n",
    "    sqe = np.sum(temp1)\n",
    "    return sqe\n",
    "\n",
    "\n",
    "center =[[1.52434 , 12.03344 , 0.01215 , 1.12869 , 71.98256 , 0.19252 , 14.34306 , 0.23039 , 0.15156],\n",
    "         [1.51956 , 13.25068 , 0.45229 , 1.53305 , 73.01401 , 0.38472 , 11.15803 , 0.00433 , 0.06599],\n",
    "         [1.51362 , 13.15690 , 0.65548 , 3.13123 , 70.50411 , 5.33024 , 6.73773  , 0.67322 , 0.01490],\n",
    "         [1.52132 , 13.74692 , 3.51952 , 1.01524 , 71.89517 , 0.21094 , 9.44764  , 0.03588 , 0.04680],\n",
    "         [1.51933 , 13.08412 , 3.52765 , 1.36555 , 72.85826 , 0.57913 , 8.36271  , 0.00837 , 0.06182],\n",
    "         [1.51567 , 14.65825 , 0.06326 , 2.21016 , 73.25324 , 0.02744 , 8.68548  , 1.02698 , 0.00382]]\n",
    "\n",
    "label = []\n",
    "for i in x_glass:\n",
    "    test = []\n",
    "    for j in center:\n",
    "        test.append(just_test(i,j))\n",
    "    label.append(np.argmin(test))\n",
    "    \n",
    "print(label)    \n",
    "print(sum_of_squares(x_glass,center,label))\n",
    "print(candidates_array[0].fitness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation algorithm \n",
    "this function do mutation algorithm on candidates interval's centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def mutation(candidate_array,mutation_random):\\n    New_candidate = copy.deepcopy(candidate_array)\\n    Mutant_candidate = copy.deepcopy(candidate_array)\\n    Trial_candidate = copy.deepcopy(candidate_array)\\n    for x in range(len(candidate_array)):\\n        a = np.full(len(candidate_array), 1/(len(candidate_array)-1))\\n        a[x] = 0\\n        temp = np.random.choice(len(candidate_array), 3, replace = False, p=a)\\n        for i in range(len(candidate_array[0].centers)):\\n            for j in range(len(candidate_array[0].centers[i])):\\n                Mutant_candidate[x].centers[i][j] = candidate_array[temp[0]].centers[i][j]+ random.random()*(candidate_array[temp[1]].centers[i][j] - candidate_array[temp[2]].centers[i][j])\\n                if random.random() < mutation_random:\\n                    Trial_candidate[x].centers[i][j] = Mutant_candidate[x].centers[i][j] #Trial & Mutant must be copy of same candidate\\n                    \\n                    \\n        Trial_candidate[x].fitness = sum_of_squares(Trial_candidate[x].nodes,Trial_candidate[x].centers,Trial_candidate[x].labels)\\n        \\n        if Trial_candidate[x].fitness < sum_of_squares(candidate_array[x].nodes,candidates_array[2].centers,candidates_array[2].labels):\\n            New_candidate[x] = Trial_candidate[x]\\n            print(\"sakjfnr\")\\n        else:\\n            New_candidate[x] = candidate_array[x]\\n        #print(Trial_candidate[x].centers)\\n        #print(candidate_array[x].centers)\\n        #print(New_candidate[x].centers)\\n        #print(Mutant_candidate[x].centers)\\n        print(\"###########################################################################################################\")\\n        Trial_candidate[x].each_fitness = each_fitness(Trial_candidate[x])\\n        print(Trial_candidate[x].each_fitness)\\n        candidate_array[x].each_fitness = each_fitness(candidate_array[x])\\n        print(candidate_array[x].each_fitness)\\n        print(\"###########################################################################################################\")\\n        \\n    return New_candidate\\n#print(candidates_array[1].fitness)\\n#for i in range(0,3500):\\nNew_candidates_array = mutation(candidates_array,mutation_random)\\n    #if New_candidates_array[1].fitness != candidates_array[1].fitness:\\n     #   print(New_candidates_array[1].fitness)#never happen'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def mutation(candidate_array,mutation_random):\n",
    "    New_candidate = copy.deepcopy(candidate_array)\n",
    "    Mutant_candidate = copy.deepcopy(candidate_array)\n",
    "    Trial_candidate = copy.deepcopy(candidate_array)\n",
    "    for x in range(len(candidate_array)):\n",
    "        a = np.full(len(candidate_array), 1/(len(candidate_array)-1))\n",
    "        a[x] = 0\n",
    "        temp = np.random.choice(len(candidate_array), 3, replace = False, p=a)\n",
    "        for i in range(len(candidate_array[0].centers)):\n",
    "            for j in range(len(candidate_array[0].centers[i])):\n",
    "                Mutant_candidate[x].centers[i][j] = candidate_array[temp[0]].centers[i][j]+ random.random()*(candidate_array[temp[1]].centers[i][j] - candidate_array[temp[2]].centers[i][j])\n",
    "                if random.random() < mutation_random:\n",
    "                    Trial_candidate[x].centers[i][j] = Mutant_candidate[x].centers[i][j] #Trial & Mutant must be copy of same candidate\n",
    "                    \n",
    "                    \n",
    "        Trial_candidate[x].fitness = sum_of_squares(Trial_candidate[x].nodes,Trial_candidate[x].centers,Trial_candidate[x].labels)\n",
    "        \n",
    "        if Trial_candidate[x].fitness < sum_of_squares(candidate_array[x].nodes,candidates_array[2].centers,candidates_array[2].labels):\n",
    "            New_candidate[x] = Trial_candidate[x]\n",
    "            print(\"sakjfnr\")\n",
    "        else:\n",
    "            New_candidate[x] = candidate_array[x]\n",
    "        #print(Trial_candidate[x].centers)\n",
    "        #print(candidate_array[x].centers)\n",
    "        #print(New_candidate[x].centers)\n",
    "        #print(Mutant_candidate[x].centers)\n",
    "        print(\"###########################################################################################################\")\n",
    "        Trial_candidate[x].each_fitness = each_fitness(Trial_candidate[x])\n",
    "        print(Trial_candidate[x].each_fitness)\n",
    "        candidate_array[x].each_fitness = each_fitness(candidate_array[x])\n",
    "        print(candidate_array[x].each_fitness)\n",
    "        print(\"###########################################################################################################\")\n",
    "        \n",
    "    return New_candidate\n",
    "#print(candidates_array[1].fitness)\n",
    "#for i in range(0,3500):\n",
    "New_candidates_array = mutation(candidates_array,mutation_random)\n",
    "    #if New_candidates_array[1].fitness != candidates_array[1].fitness:\n",
    "     #   print(New_candidates_array[1].fitness)#never happen'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336.29263337746863\n",
      "379.1282755933587\n",
      "#############################################################################################\n",
      "336.0605389372351\n",
      "336.0605389372351\n",
      "#############################################################################################\n",
      "380.4407585733279\n",
      "380.4407585733279\n",
      "#############################################################################################\n",
      "336.2131430296451\n",
      "336.2131430296451\n",
      "#############################################################################################\n",
      "338.7448885161782\n",
      "378.89950397756104\n",
      "#############################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaMeD\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py:896: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=50\n",
      "  return_n_iter=True)\n"
     ]
    }
   ],
   "source": [
    "def mutation(candidate_array,mutation_random):\n",
    "    New_candidate = copy.deepcopy(candidate_array)\n",
    "    Trial_candidate = copy.deepcopy(candidate_array)\n",
    "    for x in range(len(candidate_array)):\n",
    "        a = np.full(len(candidate_array), 1/(len(candidate_array)-1))\n",
    "        a[x] = 0\n",
    "        temp = np.random.choice(len(candidate_array), 3, replace = False, p=a)\n",
    "        Centers = []\n",
    "        for i in range(len(candidate_array[0].centers)):\n",
    "            Second_layer = []\n",
    "            for j in range(len(candidate_array[0].centers[i])):\n",
    "                temporary_Center = candidate_array[temp[0]].centers[i][j]+ random.random()*(candidate_array[temp[1]].centers[i][j] - candidate_array[temp[2]].centers[i][j])\n",
    "                if random.random() < mutation_random:\n",
    "                    Second_layer.append(temporary_Center) #Trial & Mutant must be copy of same candidate\n",
    "                else:\n",
    "                    Second_layer.append(candidate_array[x].centers[i][j])\n",
    "            Centers.append(Second_layer)\n",
    "            \n",
    "        \n",
    "        y_predict_temp,centers_temp,fitness_temp = doKmeans(candidate_array[x].nodes,clusters_count = number_of_clusters, init_centers = np.asarray(Centers))\n",
    "        if fitness_temp < candidates_array[x].fitness:\n",
    "            New_candidate[x].labels  =  y_predict_temp\n",
    "            New_candidate[x].fitness = fitness_temp\n",
    "            New_candidate[x].centers = centers_temp\n",
    "        New_candidate[x].each_fitness = each_fitness(New_candidate[c])\n",
    "        print(New_candidate[x].fitness)\n",
    "        print(candidate_array[x].fitness)\n",
    "        print(\"#############################################################################################\")\n",
    "    return New_candidate\n",
    "\n",
    "New_candidates_array = mutation(candidates_array,mutation_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1706071263073633, 0.22473042258957604, 0.16808876645701187, 0.2268351006327947, 0.0008156083052242583, 0.1831356843611011]\n",
      "[0.1706071263073633, 0.22473042258957604, 0.16808876645701187, 0.2268351006327947, 0.0008156083052242583, 0.1831356843611011]\n",
      "[0.1706071263073633, 0.22473042258957604, 0.16808876645701187, 0.2268351006327947, 0.0008156083052242583, 0.1831356843611011]\n",
      "[0.1706071263073633, 0.22473042258957604, 0.16808876645701187, 0.2268351006327947, 0.0008156083052242583, 0.1831356843611011]\n",
      "[0.31757149477054675, 0.10107830964169581, 0.32764493417195245, 0.09265959746882128, 0.9967375667791031, 0.26745726255559554]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HaMeD\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.from_iter(generator)) or the python sum builtin instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def probability(candidates):\n",
    "    for c in range(0,len(candidates)):\n",
    "        temp_array = []\n",
    "        for clusters in range(0,len(candidates[c].centers)):\n",
    "            temp_array.append((1/np.sum(candidates[c].each_fitness[clusters]))/(np.sum(1/(np.sum(x.each_fitness[clusters])) for x in candidates)))\n",
    "        print(temp_array)    \n",
    "        candidates[c].probability = temp_array\n",
    "    return\n",
    "probability(New_candidates_array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roulette Wheel Selection\n",
    "This is a logic for selecting targets with higher probability.<br>\n",
    "In this article, each candidate want to follow the other candidate with higher fitness. So in the previous section <strong><em>Probability Equation<strong><em>, we calculated all probabilities of candidates based on their fitnesses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roulette_wheel_selection(inertia_array):\n",
    "    maximum = np.sum(inertia_array)\n",
    "    pick = random.uniform(0, maximum)\n",
    "    current = 0\n",
    "    for fitness in inertia_array:\n",
    "        current += fitness\n",
    "        if current > pick:\n",
    "            return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shrink sampling interval\n",
    "**here we shrink sampeling interval using reduction factor ro creat neighborhood of each center**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.512708447368421, 1.5343494473684212], [9.576513157894738, 15.894013157894737], [-1.8732763157894734, 2.392223684210527], [-0.20264473684210516, 2.8468552631578943], [69.87578947368421, 75.1957894736842], [-2.693434210526316, 3.206065789473684], [7.4074210526315785, 17.629421052631578], [-1.3304605263157894, 1.6620394736842103], [-0.17277631578947367, 0.3117236842105263]], [[1.5055041428571427, 1.527145142857143], [11.353750000000002, 17.67125], [-1.9791785714285708, 2.2863214285714295], [0.5602500000000001, 3.60975], [70.74071428571429, 76.06071428571428], [-2.7529642857142855, 3.146535714285714], [3.5386428571428556, 13.760642857142857], [-0.5798214285714285, 2.4126785714285712], [-0.22832142857142856, 0.2561785714285714]], [[1.5108373125, 1.5324783124999999], [10.7046875, 17.022187499999998], [0.9816249999999997, 5.2471250000000005], [-0.4528749999999999, 2.5966249999999995], [69.1484375, 74.4684375], [-2.750375, 3.1491249999999997], [4.627437499999999, 14.8494375], [-1.4278125, 1.5646874999999998], [-0.1681875, 0.3163125]], [[1.5068800172413792, 1.5285210172413795], [10.33021551724138, 16.647715517241377], [1.4720775862068964, 5.737577586206896], [-0.16871551724137923, 2.8807844827586204], [69.79344827586208, 75.11344827586207], [-2.4147499999999997, 3.48475], [3.216758620689655, 13.438758620689656], [-1.4593534482758619, 1.5331465517241378], [-0.19345689655172413, 0.29104310344827583]], [[1.504152, 1.5257929999999997], [10.42875, 16.74625], [-0.6477500000000003, 3.61775], [1.4202500000000005, 4.46975], [67.92, 73.24], [0.9402500000000003, 6.83975], [1.2764999999999995, 11.4985], [-0.5387499999999998, 2.45375], [-0.24225, 0.24225]], [[1.506254705479452, 1.5278957054794522], [9.726455479452055, 16.043955479452052], [1.299852739726027, 5.565352739726027], [-0.14146232876712306, 2.9080376712328766], [70.37301369863015, 75.69301369863014], [-2.360434931506849, 3.5390650684931506], [3.335027397260273, 13.557027397260274], [-1.4895376712328765, 1.5029623287671232], [-0.16978424657534247, 0.3147157534246575]]]\n"
     ]
    }
   ],
   "source": [
    "def shrinked_sampling_interval(candidates_array):\n",
    "    for i in range(0,len(candidates_array)):\n",
    "        shrinked_sampling_interval = []\n",
    "        for j in range(0,len(candidates_array[i].centers)):\n",
    "            Second_layer = []\n",
    "            for k in range(0,len(candidates_array[i].centers[j])):\n",
    "                Third_layer = []\n",
    "                Temp = abs(candidates_array[i].sampling_interval[0][k] - candidates_array[i].sampling_interval[1][k]) * sampling_interval_reduction_factor\n",
    "                Third_layer.append(candidates_array[i].centers[j][k] - (Temp/2))\n",
    "                Third_layer.append(candidates_array[i].centers[j][k] + (Temp/2))\n",
    "                Second_layer.append(Third_layer)\n",
    "            shrinked_sampling_interval.append(Second_layer)\n",
    "        candidates_array[i].sampling_interval = shrinked_sampling_interval\n",
    "    return\n",
    "shrinked_sampling_interval(New_candidates_array)\n",
    "print(New_candidates_array[0].sampling_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variations\n",
    "**Choose t diffrent random center of each cluster's center in shrinked sampling interval neghborhood**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.5117988244923966, 15.155189210359461, 0.5698171781619015, 2.3253342215311004, 69.58700919112138, 2.995499213182032, 6.6257593298140955, 0.9783307686893449, -0.18700424046020342], [1.5290841576502885, 12.652935337255629, 5.133049724728425, 0.7514168549114606, 72.3470309592928, -1.1175628848684998, 10.773063158793498, 0.7972090131211647, -0.1273241135649642], [1.5352879223864129, 12.619903352618056, -0.24166913664207512, 2.484168482656054, 69.01348945006391, 0.39405372340485867, 15.123205441399179, 0.2242250479537351, -0.058923861837003016], [1.5227474371298468, 14.119015277272428, 5.488382368828059, 2.238806057385311, 74.75031193088418, -0.94276644752078, 3.9421140125288603, 0.4345371874485444, 0.2583066535946638], [1.5099028881957668, 16.570463870530336, -1.4217700128881214, 1.9340236662503485, 70.96755098550683, -1.5276010506326754, 12.250925975327089, 0.3775365680876084, -0.03838288865992967], [1.516517762055763, 15.390495546150232, 2.1238840548450573, 2.0453287326298666, 74.42293047103358, -0.4973305315801997, 15.430110955214188, -0.24540388515830336, 0.1630107534770113]]\n"
     ]
    }
   ],
   "source": [
    "def variation(candidates_array):\n",
    "    for candidate in candidates_array:\n",
    "        variations = []\n",
    "        for i in range(0,variations_count):\n",
    "            Second_layer = []\n",
    "            for j in candidate.sampling_interval:\n",
    "                Third_layer = []\n",
    "                for k in range(0,len(j)):\n",
    "                    #print(k)\n",
    "                    Third_layer.append(random.uniform(j[k][0],j[k][1]))\n",
    "                Second_layer.append(Third_layer)\n",
    "            variations.append(Second_layer)\n",
    "        candidate.variation = variations    \n",
    "variation(New_candidates_array)\n",
    "print(New_candidates_array[3].variation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
